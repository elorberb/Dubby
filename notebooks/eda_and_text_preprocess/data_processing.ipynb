{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:12:07.565530800Z",
     "start_time": "2024-02-17T11:12:07.206078800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f33929d3f3ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:13:14.763839Z",
     "start_time": "2024-02-17T11:13:10.876964600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30501/2041100171.py:1: DtypeWarning: Columns (0,6,7,13,15,16,18,20,22,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../../data/utterances.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/utterances.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d33d67c64f192",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will initiate data processing by primarily saving only the text and labels of the comments. For the preliminary training phase, our strategy is to deploy elementary models that utilize solely the text to evaluate their performance. Consequently, we will extract just the text and label fields and partition them into separate datasets for training, testing, and validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e0fa3b47ac59d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:23:02.947023400Z",
     "start_time": "2024-02-17T11:23:02.871204900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Look at the definition you provided, if we rem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>∆.  Yours was the first comment I read to make...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maybe a new word is needed? Making such a dist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You're using natural to mean definition 8\\n\\n&amp;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[This answer in /r/askscience does a pretty go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "1   Look at the definition you provided, if we rem...      0\n",
       "2   ∆.  Yours was the first comment I read to make...      0\n",
       "7   Maybe a new word is needed? Making such a dist...      0\n",
       "27  You're using natural to mean definition 8\\n\\n&...      0\n",
       "36  [This answer in /r/askscience does a pretty go...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Drop rows where 'meta.success' is NaN\n",
    "data = df[['text', 'meta.success']].dropna(subset=['meta.success'])\n",
    "\n",
    "# Step 2 & 4: Create 'label' column from 'meta.success' with integer type\n",
    "data['label'] = data['meta.success'].apply(lambda x: int(x == 1.0))\n",
    "\n",
    "# Step 3: Drop the 'meta.success' column\n",
    "data = data.drop(['meta.success'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62d5075680a1cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T11:17:25.175188500Z",
     "start_time": "2024-02-17T11:17:25.136260100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your DataFrame containing only the 'text' and 'label' columns\n",
    "\n",
    "# Split data into training and temporary datasets first (temporary will be split into validation and test)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temporary dataset into validation and test datasets\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Now you have train_data, validation_data, and test_data\n",
    "# Ensure the 'label' column is integer type explicitly if needed\n",
    "train_data['label'] = train_data['label'].astype(int)\n",
    "validation_data['label'] = validation_data['label'].astype(int)\n",
    "test_data['label'] = test_data['label'].astype(int)\n",
    "\n",
    "# Save to CSV files\n",
    "train_data.to_csv('../../data/train.csv', index=False)\n",
    "validation_data.to_csv('../../data/validation.csv', index=False)\n",
    "test_data.to_csv('../../data/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31752f89cb785c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Further processing if we need more stuff like processing for BERT models etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a33e723e0a5608",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dubby_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
